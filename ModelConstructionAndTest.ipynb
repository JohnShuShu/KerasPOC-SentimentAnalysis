{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exacon02/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif,chi2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Dataset from http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exacon02/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "training = np.genfromtxt('Sentiment Analysis Dataset.csv', delimiter=',', skip_header=1, usecols=(1, 3), dtype=None,max_rows=100000)\n",
    "\n",
    "train_x = [x[1] for x in training]\n",
    "train_y = np.asarray([x[0] for x in training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
    "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
    "\n",
    "    # Arguments\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of the layers.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "        num_classes: int, number of output classes.\n",
    "\n",
    "    # Returns\n",
    "        An MLP model instance.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_for_production(model, version, path='prod_models'):\n",
    "    tf.keras.backend.set_learning_phase(1)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    export_path = os.path.join(\n",
    "        tf.compat.as_bytes(path),\n",
    "        tf.compat.as_bytes(version))\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    model_input = tf.saved_model.utils.build_tensor_info(model.input)\n",
    "    model_output = tf.saved_model.utils.build_tensor_info(model.output)\n",
    "\n",
    "    prediction_signature = (\n",
    "        tf.saved_model.signature_def_utils.build_signature_def(\n",
    "            inputs={'inputs': model_input},\n",
    "            outputs={'output': model_output},\n",
    "            method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "    with tf.keras.backend.get_session() as sess:\n",
    "        builder.add_meta_graph_and_variables(\n",
    "            sess=sess, tags=[tf.saved_model.tag_constants.SERVING],\n",
    "            signature_def_map={\n",
    "                signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature,\n",
    "            })\n",
    "\n",
    "        builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "kwargs = {\n",
    "            'ngram_range': (1,2),  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': 'word',  # Split text into word tokens.\n",
    "            'min_df':  2,\n",
    "}\n",
    "vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "# Learn vocabulary from training texts and vectorize training texts.\n",
    "train_x = vectorizer.fit_transform(train_x)\n",
    "\n",
    "# Select top 'k' of the vectorized features.\n",
    "selector = SelectKBest(chi2, k=min(20000, train_x.shape[1]))\n",
    "train_x = selector.fit_transform(train_x, train_y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "80000/80000 [==============================] - 14s 181us/step - loss: 0.6461 - acc: 0.6459 - val_loss: 0.5767 - val_acc: 0.7558\n",
      "Epoch 2/20\n",
      "80000/80000 [==============================] - 14s 171us/step - loss: 0.5522 - acc: 0.7353 - val_loss: 0.5073 - val_acc: 0.7712\n",
      "Epoch 3/20\n",
      "80000/80000 [==============================] - 14s 173us/step - loss: 0.5065 - acc: 0.7587 - val_loss: 0.4790 - val_acc: 0.7821\n",
      "Epoch 4/20\n",
      "80000/80000 [==============================] - 14s 172us/step - loss: 0.4801 - acc: 0.7730 - val_loss: 0.4630 - val_acc: 0.7897\n",
      "Epoch 5/20\n",
      "80000/80000 [==============================] - 14s 172us/step - loss: 0.4620 - acc: 0.7832 - val_loss: 0.4531 - val_acc: 0.7956\n",
      "Epoch 6/20\n",
      "80000/80000 [==============================] - 14s 172us/step - loss: 0.4462 - acc: 0.7913 - val_loss: 0.4434 - val_acc: 0.7993\n",
      "Epoch 7/20\n",
      "80000/80000 [==============================] - 14s 172us/step - loss: 0.4351 - acc: 0.7957 - val_loss: 0.4373 - val_acc: 0.8023\n",
      "Epoch 8/20\n",
      "80000/80000 [==============================] - 14s 172us/step - loss: 0.4275 - acc: 0.7968 - val_loss: 0.4326 - val_acc: 0.8040\n",
      "Epoch 9/20\n",
      "80000/80000 [==============================] - 14s 178us/step - loss: 0.4196 - acc: 0.8006 - val_loss: 0.4284 - val_acc: 0.8062\n",
      "Epoch 10/20\n",
      "80000/80000 [==============================] - 14s 172us/step - loss: 0.4121 - acc: 0.8038 - val_loss: 0.4260 - val_acc: 0.8069\n",
      "Epoch 11/20\n",
      "80000/80000 [==============================] - 14s 174us/step - loss: 0.4075 - acc: 0.8061 - val_loss: 0.4236 - val_acc: 0.8066\n",
      "Epoch 12/20\n",
      "80000/80000 [==============================] - 14s 173us/step - loss: 0.4026 - acc: 0.8068 - val_loss: 0.4221 - val_acc: 0.8088\n",
      "Epoch 13/20\n",
      "80000/80000 [==============================] - 14s 172us/step - loss: 0.3993 - acc: 0.8063 - val_loss: 0.4206 - val_acc: 0.8094\n",
      "Epoch 14/20\n",
      "80000/80000 [==============================] - 14s 173us/step - loss: 0.3963 - acc: 0.8079 - val_loss: 0.4202 - val_acc: 0.8098\n",
      "Epoch 15/20\n",
      "80000/80000 [==============================] - 14s 173us/step - loss: 0.3923 - acc: 0.8099 - val_loss: 0.4201 - val_acc: 0.8092\n",
      "Epoch 16/20\n",
      "80000/80000 [==============================] - 14s 172us/step - loss: 0.3879 - acc: 0.8108 - val_loss: 0.4187 - val_acc: 0.8104\n",
      "Epoch 17/20\n",
      "80000/80000 [==============================] - 14s 173us/step - loss: 0.3864 - acc: 0.8119 - val_loss: 0.4183 - val_acc: 0.8106\n",
      "Epoch 18/20\n",
      "80000/80000 [==============================] - 14s 173us/step - loss: 0.3827 - acc: 0.8119 - val_loss: 0.4183 - val_acc: 0.8112\n"
     ]
    }
   ],
   "source": [
    "# Defining the parameters for the model\n",
    "layers=2\n",
    "units=32\n",
    "dropout_rate=0.3\n",
    "input_shape=train_x.shape[1:]\n",
    "num_classes=2\n",
    "\n",
    "\n",
    "# Create model instance.\n",
    "model=mlp_model(layers,units,dropout_rate,input_shape,num_classes)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "# Train and validate model.\n",
    "model.fit(train_x, train_y,\n",
    "  batch_size=512,\n",
    "  epochs=20,\n",
    "  verbose=1,\n",
    "  validation_split=0.2,\n",
    "  callbacks = [EarlyStopping(monitor='val_loss', patience=1)],     \n",
    "  shuffle=True)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a sentence to be evaluated, or Enter to quit: i am happy\n",
      "  (0, 9311)\t0.44521123\n",
      "  (0, 1562)\t0.8048806\n",
      "  (0, 1548)\t0.39236996\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.9931793]]\n",
      "Positive Sentiment.Confidence Level: 98.6358642578125 %\n",
      "Input a sentence to be evaluated, or Enter to quit: i am not happy\n",
      "  (0, 13315)\t0.61494946\n",
      "  (0, 13261)\t0.2730108\n",
      "  (0, 9311)\t0.38012007\n",
      "  (0, 1573)\t0.53905755\n",
      "  (0, 1548)\t0.33500436\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.03063744]]\n",
      "Negative Sentiment.Confidence Level: 93.87251175940037 %\n",
      "Input a sentence to be evaluated, or Enter to quit: \n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('model.h5')\n",
    "while 1:\n",
    "    evalSentence =input('Input a sentence to be evaluated, or Enter to quit: ')\n",
    "\n",
    "    if len(evalSentence) == 0:\n",
    "        break\n",
    "\n",
    "    # Format your input for the neural net\n",
    "    evalSentence=[evalSentence]\n",
    "    tx = vectorizer.transform(evalSentence).astype('float32')\n",
    "    tx = selector.transform(tx).astype('float32')\n",
    "    print(tx)\n",
    "    print(tx.todense())\n",
    "    pred = model.predict(tx)\n",
    "    print(pred)\n",
    "    if pred[0][0]>0.5:\n",
    "        print(\"Positive Sentiment.Confidence Level:\",(pred[0][0]-0.5)*200,\"%\")\n",
    "    else:\n",
    "        print(\"Negative Sentiment.Confidence Level:\",(0.5-pred[0][0])*200,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/exacon02/Models/Sentiment/Test/1/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "#This function saves the model and weights in the .pb format and also freezes and saves the variables\n",
    "save_model_for_production(model, \"1\", \"/Sentiment\")\n",
    "#Put the Path of the Directory you wish to save your model in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
